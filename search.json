[
  {
    "objectID": "content/01_journal/01_tidyverse.html",
    "href": "content/01_journal/01_tidyverse.html",
    "title": "Tidyverse",
    "section": "",
    "text": "1 Challenge 1.1 Analyze of the sales by location\nThe following figure shows the bar plot for sales by each state. As can be seen from Fig. 1, the State of NRW has the highest revenue of 21.200.613 euro.\n\n\nFig. 1 Bar Plot of sales for each state in Germany\n\n\n\n2 Challenge 1.2 Analyze of the sales by location and year\nFigure 2 shows the bar plot for sales by each state and each year.\n\n\nFig. 2 Bar Plot of sales for each state in Germany\n\n\n\n3 Source Code\n\n# Data Science at TUHH ------------------------------------------------------\n# SALES ANALYSIS ----\n\n# 1.0 Load libraries ----\nlibrary(tidyverse)\n\n#> -- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\n#> v dplyr     1.1.2     v readr     2.1.4\n#> v forcats   1.0.0     v stringr   1.5.0\n#> v ggplot2   3.4.2     v tibble    3.2.1\n#> v lubridate 1.9.2     v tidyr     1.3.0\n#> v purrr     1.0.1     \n#> -- Conflicts ------------------------------------------ tidyverse_conflicts() --\n#> x dplyr::filter() masks stats::filter()\n#> x dplyr::lag()    masks stats::lag()\n#> i Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nlibrary(readxl)\n\n# 2.0 Importing Files ----\nbikes_tbl      <- read_excel(path = \"../../00_data/01_bike_sales/01_raw_data/bikes.xlsx\")\norderlines_tbl <- read_excel(\"../../00_data/01_bike_sales/01_raw_data/orderlines.xlsx\")\n\n#> New names:\n#> * `` -> `...1`\n\n# Not necessary for this analysis, but for the sake of completeness\nbikeshops_tbl  <- read_excel(\"../../00_data/01_bike_sales/01_raw_data/bikeshops.xlsx\")\n\n# 3.0 Examining Data ----\n\n\n# 4.0 Joining Data ----\nbike_orderlines_joined_tbl <- orderlines_tbl %>%\n  left_join(bikes_tbl, by = c(\"product.id\" = \"bike.id\")) %>%\n  left_join(bikeshops_tbl, by = c(\"customer.id\" = \"bikeshop.id\"))\n\n# 5.0 Wrangling Data ----\n\n\nbike_orderlines_wrangled_tbl <- bike_orderlines_joined_tbl %>% \n  # 5.1 Separate location\n  separate(col    = location,\n           into   = c(\"city\", \"state\"),\n           sep    = \", \") %>%\n  # 5.2 Add the total price (price * quantity) \n  # Add a column to a tibble that uses a formula-style calculation of other columns\nmutate(total.price = price * quantity) \n\n\n\n# 5.3 Optional: Reorganize. Using select to grab or remove unnecessary columns\n# 5.3.1 by exact column name\nbike_orderlines_wrangled_tbl_reorg<- bike_orderlines_wrangled_tbl %>% select(-...1, -gender)%>% \n  \n  # 5.3.2 by a pattern\n  # You can use the select_helpers to define patterns. \n  # Type ?ends_with and click on Select helpers in the documentation\n  select(-ends_with(\".id\")) %>%\n  \n  # 5.3.3 Actually we need the column \"order.id\". Let's bind it back to the data\n  bind_cols(bike_orderlines_joined_tbl %>% select(order.id)) \n\n# 5.3.4 You can reorder the data by selecting the columns in your desired order.\n# You can use select_helpers like contains() or everything()\nbike_orderlines_wrangled_tbl_reorg_reorder <- bike_orderlines_wrangled_tbl_reorg %>% select(order.id, contains(\"order\"), contains(\"model\"), contains(\"category\"),\n                                                                                            price, quantity, total.price,\n                                                                                            everything()) %>%\n  # 5.4 Rename columns because we actually wanted underscores instead of the dots\n  # (one at the time vs. multiple at once)\n  rename(bikeshop = name) %>%\n  set_names(names(.) %>% str_replace_all(\"\\\\.\", \"_\"))\n\n# 6.0 Business Insights ----\n\n# 6.1 Sales by State ----\n\n# Step 1 - Manipulate\n\nlibrary(lubridate)\n# Step 1 - Manipulate\nsales_by_state_tbl <- bike_orderlines_wrangled_tbl_reorg_reorder %>%\n  \n  # Select columns\n  select(state, total_price) %>%\n  \n  \n  # Grouping by year and summarizing sales\n  group_by(state) %>%\n  summarize(sales = sum(total_price))%>%\n  \n  # Optional: Add a column that turns the numbers into a currency format \n  # (makes it in the plot optically more appealing)\n  # mutate(sales_text = scales::dollar(sales)) <- Works for dollar values\n  mutate(sales_text = scales::dollar(sales, big.mark = \".\", \n                                     decimal.mark = \",\", \n                                     prefix = \"\", \n                                     suffix = \" €\"))\n\nsales_by_state_tbl\n\n\n\n  \n\n\n# Step 2 - Visualize\nsales_by_state_tbl %>%\n  \n  # Setup canvas with the columns state (x-axis) and sales (y-axis)\n  ggplot(aes(x = state, y = sales)) +\n  \n  # Geometries\n  geom_col(fill = \"#FFC300\") + # Use geom_col for a bar plot\n  geom_label(aes(label = sales_text)) + # Adding labels to the bars\n  \n  \n  # Formatting\n  # scale_y_continuous(labels = scales::dollar) + # Change the y-axis. \n  # Again, we have to adjust it for euro values\n  scale_y_continuous(labels = scales::dollar_format(big.mark = \".\", \n                                                    decimal.mark = \",\", \n                                                    prefix = \"\", \n                                                    suffix = \" €\")) +\n  labs(\n    title    = \"Revenue by state\",\n    x = \"\", # Override defaults for x and y\n    y = \"Revenue\" \n  )+ theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n# 6.2 Sales by state and year  ----\n\n# Step 1 - Manipulate\nsales_by_state_year_tbl <- bike_orderlines_wrangled_tbl_reorg_reorder %>%\n  \n  # Select columns and add a year\n  select(order_date, total_price, state) %>%\n  mutate(year = year(order_date)) %>%\n  \n  # Group by and summarize state and year\n  group_by(state, year) %>%\n  summarise(sales = sum(total_price)) %>%\n  ungroup() %>%\n  \n  # Format $ Text\n  mutate(sales_text = scales::dollar(sales, big.mark = \".\", \n                                     decimal.mark = \",\", \n                                     prefix = \"\", \n                                     suffix = \" €\"))\n\n#> `summarise()` has grouped output by 'state'. You can override using the\n#> `.groups` argument.\n\nsales_by_state_year_tbl\n\n\n\n  \n\n\n# Step 2 - Visualize\n\nsales_by_state_year_tbl %>%\n  \n  # Set up x, y, fill\n  ggplot(aes(x = year, y = sales, fill = state)) +\n  \n  # Geometries\n  geom_col() + # Run up to here to get a stacked bar plot\n# Facet\nfacet_wrap(~ state) +\n  \n  \n  \n  # Formatting\n  scale_y_continuous(labels = scales::dollar_format(big.mark = \".\", \n                                                    decimal.mark = \",\", \n                                                    prefix = \"\", \n                                                    suffix = \" €\")) +\n  labs(\n    title = \"Revenue by state and year\",\n    fill = \"year\" # Changes the legend name\n  )+ theme(axis.text.x = element_text(angle = 90, hjust = 1))"
  },
  {
    "objectID": "content/01_journal/02_data_acquisition.html",
    "href": "content/01_journal/02_data_acquisition.html",
    "title": "Data Acquisition",
    "section": "",
    "text": "1 Challenge: Get Data via an API\nIn this code, occurrence data for the honeybee species was fetched using the GBIF API. The latitude and longitude of the occurrences were then plotted on a map of the world using the ggplot2 and maps packages in R. The resulting plot (Fig. 1) shows the distribution of honeybee occurrences (the fetched data is primarily for America continent).\n\n\nFig. 1 The Bio-diversity scatter plot of Honey Bee\n\n\n\n2 Scrape one of the competitor websites of canyon (either https://www.rosebikes.de/ or https://www.radon-bikes.de) and create a small database\nUnfortunately, I was not able to get the hang of html structure and do scraping. So I will leave this part Blank\n\n3 Source code\n\n# Load required libraries\nlibrary(httr)\nlibrary(jsonlite)\n\n# Define API endpoint and parameters\napi_url <- \"https://api.gbif.org/v1/occurrence/search\"\nparams <- list(\n  taxonKey = 2435098, # Taxon key for the species (e.g., 2435098 for \"Apis mellifera\" - the honeybee)\n  limit = 300         # Number of records to fetch (max 300)\n)\n\n# Send GET request to the API\nresponse <- GET(api_url, query = params)\n\n\n\n# Check the HTTP status code\nstatus_code <- status_code(response)\nif (status_code == 200) {\n  # Successful response\n  print(\"Request successful!\")\n  # Parse JSON response\n  json_data <- content(response, as = \"text\", encoding = \"UTF-8\")\n  data <- fromJSON(json_data, flatten = TRUE)\n  \n  # Convert the results to a dataframe\n  occurrences_df <- as.data.frame(data$results)\n  \n  # Print the dataframe\n\n} else {\n  # Unsuccessful response\n  print(paste(\"Request failed with status code:\", status_code))\n}\n\n#> [1] \"Request successful!\"\n\n# Load required libraries\nlibrary(ggplot2)\nlibrary(ggmap)\nlibrary(maps)\n\n# Remove rows with missing latitude or longitude\noccurrences_df <- occurrences_df[!is.na(occurrences_df$decimalLatitude) & !is.na(occurrences_df$decimalLongitude),]\n\n# Get the world map data\nworld_map <- map_data(\"world\")\n\n# Create a ggplot object with the world map\nmap_plot <- ggplot() +\n  geom_polygon(data = world_map, aes(x = long, y = lat, group = group), fill = \"gray80\", color = \"gray50\") +\n  theme_minimal()\n\n# Add the scatter plot of latitude and longitude on top of the map\nmap_plot + geom_point(data = occurrences_df, aes(x = decimalLongitude, y = decimalLatitude), color = \"blue\", alpha = 0.5) +\n  labs(title = \"Bio-diversity of Honey Bees\", x = \"Longitude\", y = \"Latitude\")"
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html",
    "href": "content/01_journal/03_data_wrangling.html",
    "title": "Data Wrangling",
    "section": "",
    "text": "1 Question 1: Patent Dominance\nWhat US company / corporation has the most patents? List the 10 US companies with the most assigned/granted patents. Table 1 shows the top 10 Companies.\nTable 1: The Top 10 Companies with the Most Assigned/Granted Patents\n\n\n\n\n\n\n\nRank\nOrganization\nNumber of Patents\n\n\n\n1\nInternational Business Machines Corporation\n7547\n\n\n2\nSamsung Electronics Co., Ltd.\n5835\n\n\n3\nCanon Kabushiki Kaisha\n4099\n\n\n4\nSony Corporation\n3326\n\n\n5\nMicrosoft Corporation\n3165\n\n\n6\nGoogle Inc.\n2668\n\n\n7\nKabushiki Kaisha Toshiba\n2656\n\n\n8\nQUALCOMM Incorporated\n2597\n\n\n9\nLG Electronics Inc.\n2459\n\n\n10\nPanasonic Corporation\n2218\n\n\n\n2 Question 2: Recent Patent Activity\nWhat US company had the most patents granted in August 2014? List the top 10 companies with the most new granted patents for August 2014. Table 2 shows the top 10 companies in August 2014.\nTable 2: The Top 10 Companies with the Most Assigned/Granted Patents in August 2014\n\n\n\n\n\n\n\nRank\nOrganization\nNumber of Patents\n\n\n\n1\nInternational Business Machines Corporation\n718\n\n\n2\nSamsung Electronics Co., Ltd.\n524\n\n\n3\nCanon Kabushiki Kaisha\n361\n\n\n4\nMicrosoft Corporation\n337\n\n\n5\nSony Corporation\n269\n\n\n6\nGoogle Inc.\n240\n\n\n7\nQUALCOMM Incorporated\n223\n\n\n8\nApple Inc.\n222\n\n\n9\nKabushiki Kaisha Toshiba\n213\n\n\n10\nLG Electronics Inc.\n211\n\n\n\n3 Question 3: Innovation in Tech\nWhat is the most innovative tech sector? For the top 10 companies (worldwide) with the most patents, what are the top 5 USPTO tech main classes? The following table shows the top 5 tech main classes.\nTable 3: Top 5 USPTO Tech Main Classes\n\n\nRank\nMain Class ID\nNumber of Patents\n\n\n\n1\n257\n7956\n\n\n2\n455\n6120\n\n\n3\n370\n5448\n\n\n4\n348\n4102\n\n\n5\n709\n4010\n\n\n\n#Source Code\n\n# Data Wrangling\n\nlibrary(vroom)\nlibrary(data.table)\n\ncol_types <- list(\n  id = col_character(),\n  type = col_character(),\n  date = col_date(\"%Y-%m-%d\"),\n  num_claims = col_double()\n)\n\n# Load the patent data\npatent_data <- vroom(\n  file = \"../../reduced_data/patent.tsv\", \n  delim = \"\\t\", \n  col_types = col_types,\n  na = c(\"\", \"NA\", \"NULL\")\n)\n\n#> Warning: The following named parsers don't match the column names: type\n\npatent_assignee_data <- vroom(\n  file = \"../../reduced_data/patent_assignee.tsv\", \n  delim = \"\\t\", \n  col_types = col_types,\n  na = c(\"\", \"NA\", \"NULL\")\n)\n\n#> Warning: The following named parsers don't match the column names: id, type,\n#> date, num_claims\n\nassignee_data <- vroom(\n  file = \"../../reduced_data/assignee.tsv\", \n  delim = \"\\t\", \n  col_types = col_types,\n  na = c(\"\", \"NA\", \"NULL\")\n)\n\n#> Warning: The following named parsers don't match the column names: date,\n#> num_claims\n\nuspc_data <- vroom(\n  file = \"../../reduced_data/uspc.tsv\", \n  delim = \"\\t\", \n  col_types = col_types,\n  na = c(\"\", \"NA\", \"NULL\")\n)\n\n#> Warning: The following named parsers don't match the column names: id, type,\n#> date, num_claims\n\n# Convert data to data.table format\nsetDT(patent_data)\nsetDT(assignee_data)\nsetDT(patent_assignee_data)\nsetDT(uspc_data)\n\n#> Warning: One or more parsing issues, call `problems()` on your data frame for details,\n#> e.g.:\n#>   dat <- vroom(...)\n#>   problems(dat)\n\nclass(assignee_data)\n\n#> [1] \"data.table\" \"data.frame\"\n\n# First Question: Data Table Production\ncolnames(assignee_data)\n\n#> [1] \"id\"           \"type\"         \"organization\"\n\nsetnames(assignee_data, \"id\", \"assignee_id\")\nq1_data <- merge(x = assignee_data, y = patent_assignee_data, by = \"assignee_id\")\n\n# 1st Answer: Calculate total number of patents per assignee and organization\nsetDT(q1_data)\ntotal_patents <- q1_data[, .(n_patents = .N), by = .(assignee_id, organization)][order(-n_patents)]\ntop_10_US_patentholders <- total_patents[1:10]\n# Print the top 10 US patent holders\nprint(top_10_US_patentholders)\n\n#>                  assignee_id                                organization\n#>  1: org_ONzMjdbZXiKfw4L0cXl6 International Business Machines Corporation\n#>  2: org_pCbqlmAg8wlWzoi18ITD               Samsung Electronics Co., Ltd.\n#>  3: org_eAKK85fawH0NS7AdXOig                      Canon Kabushiki Kaisha\n#>  4: org_g8U335TH48QmGJOIQnNl                            Sony Corporation\n#>  5: org_LKW5uc4C9BNTBapFdHzJ                       Microsoft Corporation\n#>  6: org_LRPLF1XVb00MQdPndIbu                                 Google Inc.\n#>  7: org_EccJQIigrq4WyGinD0b8                    Kabushiki Kaisha Toshiba\n#>  8: org_adUSPYdjFbyHvoVakUrc                       QUALCOMM Incorporated\n#>  9: org_dfvuIWENawcU6lTd1Z3w                         LG Electronics Inc.\n#> 10: org_h5J6cVWyUahTuvNuksTb                       Panasonic Corporation\n#>     n_patents\n#>  1:      7547\n#>  2:      5835\n#>  3:      4099\n#>  4:      3326\n#>  5:      3165\n#>  6:      2668\n#>  7:      2656\n#>  8:      2597\n#>  9:      2459\n#> 10:      2218\n\n# Export the dataframe to CSV\nfile_path <- \"../../exported_data/top_10_US_patentholders.csv\"\nwrite.csv(top_10_US_patentholders, file = file_path, row.names = FALSE)\n# Display a message to confirm the export\ncat(\"Dataframe exported successfully to\", file_path, \"\\n\")\n\n#> Dataframe exported successfully to ../../exported_data/top_10_US_patentholders.csv\n\n# Second Question: Data Table Production\ncolnames(patent_data)\n\n#> [1] \"id\"         \"date\"       \"num_claims\"\n\nsetnames(patent_data, \"id\", \"patent_id\")\nq2_data <- merge(x = q1_data, y = patent_data, by = \"patent_id\")\n\n# 2nd Answer: Retrieve data for August 2014 and count patents per organization\naugust_data <- q2_data[month(date) == 8 & year(date) == 2014]\n\n# Group the data by organization and calculate the total number of patents for each organization.\ntotal_patents <- august_data[, .(num_patents = .N), by = organization]\n\n# Sort the results in descending order based on the number of patents and select the top 10 entries.\ntop_10_comp <- total_patents[order(-num_patents)][1:10]\n\n# Display the top 10 organizations that hold the highest number of patents in August 2014.\nas.data.table(top_10_comp)\n\n\n\n  \n\n\n# Export the dataframe to CSV\nfile_path <- \"../../exported_data/top_10_US_August2014.csv\"\nwrite.csv(top_10_comp, file = file_path, row.names = FALSE)\n# Display a message to confirm the export\ncat(\"Dataframe exported successfully to\", file_path, \"\\n\")\n\n#> Dataframe exported successfully to ../../exported_data/top_10_US_August2014.csv\n\n# Third Question: Data Table Production\nuspc_data[, patent_id := as.character(patent_id)]\nq3_data <- merge(x = uspc_data, y = q1_data, by = \"patent_id\")\n\n# 3rd Answer: Analyze patents assigned to top 10 companies and count patents per technology class\n# Perform a grouping operation on the data based on the organization and determine the count of patents for each group\ntotal_patents <- q3_data[, .(num_patents = .N), by = organization]\n\n# Sort the results in descending order based on the number of patents and select the top 10 entries\ntop_10_comp_patent <- total_patents[order(-num_patents)][1:10]\n\n# Filter the data to only include patents assigned to the top 10 companies\ntop_10_comp_patent <- q3_data[organization %in% top_10_comp_patent$organization]\n\n# Group the data by USPTO tech main class and count the number of patents\nmainclass_total <- top_10_comp_patent[, .(num_patents = .N), by = mainclass_id]\n\n# Order the results by number of patents in descending order and subset the top 5 technology classes\ntop_5_mainclass <- mainclass_total[order(-num_patents)][1:5]\n\n# Print the the top 5 USPTO tech main classes\nprint(top_5_mainclass)\n\n#>    mainclass_id num_patents\n#> 1:          257        7956\n#> 2:          455        6120\n#> 3:          370        5448\n#> 4:          348        4102\n#> 5:          709        4010\n\n# Export the dataframe to CSV\nfile_path <- \"../../exported_data/top_5_mainclass.csv\"\nwrite.csv(top_5_mainclass, file = file_path, row.names = FALSE)\n# Display a message to confirm the export\ncat(\"Dataframe exported successfully to\", file_path, \"\\n\")\n\n#> Dataframe exported successfully to ../../exported_data/top_5_mainclass.csv"
  },
  {
    "objectID": "content/01_journal/04_data_visualization.html",
    "href": "content/01_journal/04_data_visualization.html",
    "title": "Data Visualization",
    "section": "",
    "text": "The following figure shows the time series of total confirmed cases of Covid-19 for selected countries.\n\n\nFig. 1 Total Confirmed Cases of Covid-19"
  },
  {
    "objectID": "content/01_journal/04_data_visualization.html#challenge-1",
    "href": "content/01_journal/04_data_visualization.html#challenge-1",
    "title": "Data Visualization",
    "section": "\n3.1 Challenge 1",
    "text": "3.1 Challenge 1\n\n# Data Visualization\n\n# Challenge 1\n\n# Load required libraries\nlibrary(tidyverse)   # For data manipulation and visualization\n\n#> -- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\n#> v dplyr     1.1.2     v readr     2.1.4\n#> v forcats   1.0.0     v stringr   1.5.0\n#> v ggplot2   3.4.2     v tibble    3.2.1\n#> v lubridate 1.9.2     v tidyr     1.3.0\n#> v purrr     1.0.1     \n#> -- Conflicts ------------------------------------------ tidyverse_conflicts() --\n#> x dplyr::filter() masks stats::filter()\n#> x dplyr::lag()    masks stats::lag()\n#> i Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nlibrary(ggrepel)    # For label repulsion in plots\nlibrary(scales)      # For customizing scale labels\n\n#> \n#> Attaching package: 'scales'\n#> \n#> The following object is masked from 'package:purrr':\n#> \n#>     discard\n#> \n#> The following object is masked from 'package:readr':\n#> \n#>     col_factor\n\nlibrary(lubridate)   # For working with dates\nSys.setlocale(\"LC_TIME\", \"English\")  # Set English locale for date formatting\n\n#> [1] \"English_United States.1252\"\n\n# Read the COVID-19 data from the provided URL\nworld_cov_data <- read_csv(\"https://covid.ourworldindata.org/data/owid-covid-data.csv\")\n\n#> Rows: 313070 Columns: 67\n#> -- Column specification --------------------------------------------------------\n#> Delimiter: \",\"\n#> chr   (4): iso_code, continent, location, tests_units\n#> dbl  (62): total_cases, new_cases, new_cases_smoothed, total_deaths, new_dea...\n#> date  (1): date\n#> \n#> i Use `spec()` to retrieve the full column specification for this data.\n#> i Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Select only the relevant columns: date, continent, location, and total_cases\nworld_cov_data <- world_cov_data %>% \n  select(date, continent, location, total_cases) %>% \n  filter(!is.na(total_cases))\n\n# Convert the date column to Date format\nworld_cov_data$date <- as.Date(world_cov_data$date)\n\n# Select data for chosen countries\nchosen_count <- c(\"Europe\", \"France\", \"Germany\", \"Spain\", \"United Kingdom\", \"United States\")\nchosen_data <- world_cov_data %>% filter(location %in% chosen_count)\n\n# Create a vector of distinct colors\nline_colors <- c(\"#FF0000\", \"#00FF00\", \"#0000FF\", \"#FF00FF\", \"#FFFF00\", \"#00FFFF\")\n\n# Create the plot\nggplot(chosen_data, aes(x = date, y = total_cases, color = location, group = location)) +\n  geom_line(size = 1) +\n  geom_label_repel(data = chosen_data %>% filter(date == max(date)), aes(label = location, x = date, y = total_cases),\n                   size = 4, box.padding = unit(0.5, \"lines\"), point.padding = unit(0.4, \"lines\"), show.legend = FALSE) +\n  labs(title = \"Covid-19 Confirmed Cases Worldwide\", subtitle = \"Data as of 25/05/2023\", y = \"Cumulative Cases\", x = \"Continent/Country\") +\n  scale_y_continuous(labels = function(x) format(x/1e6, big.mark = \" \", scientific = FALSE) %>% paste0(\" \", \"M\")) +\n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%B '%y\") +\n  scale_color_manual(values = line_colors) +\n  theme(plot.title = element_text(hjust = 0.5),\n        axis.text.x = element_text(angle = 45, hjust = 1),\n        legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.margin = margin(t = 10),\n        legend.box = \"horizontal\",\n        legend.box.just = \"center\",\n        legend.spacing.x = unit(0.1, \"cm\"))\n\n#> Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#> i Please use `linewidth` instead."
  },
  {
    "objectID": "content/01_journal/04_data_visualization.html#chalenge-2",
    "href": "content/01_journal/04_data_visualization.html#chalenge-2",
    "title": "Data Visualization",
    "section": "\n3.2 Chalenge 2",
    "text": "3.2 Chalenge 2\n\n# Data Visualization\n## Challenge 2\n\n# Load required libraries\nlibrary(tidyverse)   # For data manipulation and visualization\nlibrary(maps)       # For map data and plotting geographic maps\n\n#> \n#> Attaching package: 'maps'\n\n\n#> The following object is masked from 'package:purrr':\n#> \n#>     map\n\nlibrary(mapdata)    # Additional map datasets for use with maps package\nlibrary(ggplot2)    # For creating visually appealing and customizable graphics\nlibrary(scales)     # Customizing scale labels in plots\n\n# Read the COVID-19 data from the provided URL\nworld_cov_data <- read_csv(\"https://covid.ourworldindata.org/data/owid-covid-data.csv\")\n\n#> Rows: 313070 Columns: 67\n\n\n#> -- Column specification --------------------------------------------------------\n#> Delimiter: \",\"\n#> chr   (4): iso_code, continent, location, tests_units\n#> dbl  (62): total_cases, new_cases, new_cases_smoothed, total_deaths, new_dea...\n#> date  (1): date\n#> \n#> i Use `spec()` to retrieve the full column specification for this data.\n#> i Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Select only the relevant columns: date, location, population, total_cases, total_deaths\nworld_cov_data <- world_cov_data %>% \n  select(date, location, population, total_cases, total_deaths) %>% \n  filter(!is.na(total_cases), !is.na(total_deaths))\n\n# Calculate mortality rate by dividing the total deaths by the population\nmort_rate <- world_cov_data$total_deaths / world_cov_data$population\nworld_cov_data <- world_cov_data %>% mutate(mortality_rate = mort_rate)\n\n# Select the most recent data for each location\nrecent_data <- world_cov_data %>% \n  group_by(location) %>% \n  slice_tail(n = 1)\n\n# Align country names to match the names used in the map data\nrecent_data <- recent_data %>% \n  mutate(location = case_when(\n    location == \"United Kingdom\" ~ \"UK\",\n    location == \"United States\" ~ \"USA\",\n    location == \"Democratic Republic of Congo\" ~ \"Democratic Republic of the Congo\",\n    TRUE ~ location\n  )) %>% \n  distinct()\n\n# Merge the data with map data\nworld_mp_data <- map_data(\"world\")\nworld_map_data <- right_join(world_mp_data, recent_data, by = c(\"region\" = \"location\"))\n\n# Plotting the map\nplot_data <- ggplot() +\n  geom_map(data = world_map_data, map = world_map_data, aes(map_id = region, fill = mortality_rate),\n           color = \"white\", size = 0.1) +\n  expand_limits(x = world_mp_data$long, y = world_mp_data$lat) +\n  scale_fill_gradient(low = \"red\", high = \"black\", name = \"Mortality Rate\",\n                      labels = scales::percent_format()) +\n  labs(title = \"Confirmed COVID-19 deaths relative to the size of the population\",\n       subtitle = \"Around 6.9 Million confirmed COVID-19 deaths worldwide (May 2023)\") +\n  theme_void() +\n  theme(plot.title = element_text(hjust = 0.5, size = 11, face = \"bold\"),\n        plot.subtitle = element_text(hjust = 0.5, size = 9),\n        legend.position = \"right\",\n        legend.title.align = 0.5,\n        legend.text = element_text(size = 7),\n        legend.title = element_text(size = 9),\n        panel.background = element_rect(fill = \"transparent\", color = \"white\"))\n\nprint(plot_data)"
  },
  {
    "objectID": "content/03_other/06_links.html",
    "href": "content/03_other/06_links.html",
    "title": "Links",
    "section": "",
    "text": "R is a free open-source programming language that can be used for statistical analysis, data-simulation, graphing, and lots of other stuff. Another free program is R-studio, that provides a nice graphic interface for R. Download R first, then download R-studio. Both can run on PCs, Macs or Linux. Students will be learning R in the stats labs using the lab manual .\n\n\n\n\nGoogle is great, Google your problem\nStackoverflow is great, google will often take you there because someone has already asked your question, and someone else has answered, usually many people have answered your question many ways."
  },
  {
    "objectID": "index.html#explore-my-projects",
    "href": "index.html#explore-my-projects",
    "title": "My Lab Journal",
    "section": "Explore my Projects",
    "text": "Explore my Projects\nOn this website, you will find a collection of my projects, showcasing the practical application of Business Data Science. I invite you to explore the intricacies of each task, witnessing firsthand how data can revolutionize decision-making."
  },
  {
    "objectID": "index.html#join-me-on-this-exciting-journey",
    "href": "index.html#join-me-on-this-exciting-journey",
    "title": "My Lab Journal",
    "section": "Join me on this Exciting Journey",
    "text": "Join me on this Exciting Journey\nI am thrilled to share my accomplishments with you and demonstrate the profound impact that data-driven insights can have on businesses of all scales. Whether you are a fellow learner, an industry professional, or simply an enthusiast of the data science realm, I hope that my work inspires you and sparks a curiosity to further explore this fascinating field.\nHappy exploring!\n[Shahrokh Vahedi]"
  }
]